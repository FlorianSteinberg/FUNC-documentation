\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[ngerman]{babel}
\usepackage{xspace,listings,color}
\usepackage[colorlinks=true]{hyperref}
\usepackage{amsmath, amssymb}
\usepackage{cleveref}

\definecolor{commentgray}{rgb}{0.4,0.4,0.4}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{keywordred}{rgb}{0.7,0.1,0.1}
\definecolor{stringyellow}{rgb}{0.7,0.5,0.82}
\lstset{backgroundcolor=\color{white},
	basicstyle=\footnotesize,     
	breakatwhitespace=false,      
	breaklines=true,              
	captionpos=b,                 
	commentstyle=\color{commentgray}, 
	deletekeywords={...},         
	escapeinside={\%*}{*)},       
	keywordstyle=\color{keywordred},    
	language=C++,              
	morekeywords={*,...},         
	numbers=left,                 
	numbersep=5pt,                
	numberstyle=\tiny\color{gray},
	rulecolor=\color{black},      
	showspaces=false,             
	showstringspaces=false,       
	showtabs=false,               
	stringstyle=\color{stringyellow},
	tabsize=2,
	belowskip=.25cm}

\DeclareMathOperator{\NN}{\ensuremath{\mathbb{N}}\xspace}

\newcommand{\irram}{\texttt{iRRAM}\xspace}
\newcommand{\irrams}{\texttt{iRRAM}s\xspace}
\newcommand{\cc}{\texttt{C++}\xspace}
\newcommand{\ccOx}{\texttt{C++11}\xspace}
\newcommand{\ir}[1]{\texttt{#1}\xspace}
\newcommand{\code}[1]{\texttt{#1}\xspace}
\newcommand{\func}[1]{\texttt{#1}\xspace}
\newcommand{\NULL}{\texttt{NULL} pointer\xspace}
\newcommand{\temp}[1]{\textcolor{red}{#1}}

\begin{document}
\tableofcontents
\setcounter{section}{-1}
\section{Introduction}

We aim to implement a type of analytic functions in \irram. The \irram is a \cc package for error-free real arithmetic. We will begin by summarizing the facts about computable analytic functions we need. We will go on to describe some of the key features of \irram. The we will present some parts of the \ccOx standard template library we need for implementation. Finally we will describe how the implementation was done. In the last chapter we will address some shortcomings and possible future improvements.

\section{Computable analytic functions}

We will only consider analytic functions, that are equal to their Taylor expansion around zero on a open superset of the Unit disc. This means, that we can find some $r>1$ which is still strictly smaller than the radius of convergence. In the following we will fix such a function $f$.

$f$ is uniquely determined by its Taylor-series in zero. In the following, we will denote the Taylor-series of $f$ by $(a_n)_{n\in \NN}$. It can be expressed in terms of $f$s derivatives, or by Cauchy's differentiation formula:
\[ a_n = \frac{f^{(n)}(0)}{n!} = \frac 1 {2\pi i}\int_{|z| = r} \frac{f(z)}{|z|^{n+1}} d\lambda. \]
The sequence $(a_n)_{n\in \NN}$ is computable if and only if $f$ is computable (as continuous function). 

Unfortunately it is not possible to evaluate such a function effectively without further information. We additionally need two constants $k$ and $A$. $k$ will be such, that $r:=\sqrt[k]{2}$ is still smaller than the radius of convergence of $(a_n)_{n\in \NN}$ and $A$ such that for all $n\in \NN$
\[ |a_n|  r^n \leq A. \]
Since we demanded a convergence radius strictly larger than 1, constants like this will always exist.

We will briefly discuss how these constants can be found: Since the radius of convergence of $f$ is assumed to be strictly larger than $1$, and $r:=\sqrt[k] 2$ goes to $1$ as $k$ goes to infinity, it is possible to choose $k$ big enough for $r$ to be in between $1$ and the radius of convergence. Now fix such an $k$. Consider the function
\[ f|_{\{z:|z| = r\}}. \]
Since this is a continuous function on a compact domain, it will be bounded. If $A$ is a bound of this function, the Cauchy differentiation formula gives:
\[ |a_n |=  \left|\frac 1 {2\pi i}\int_{|z| = r} \frac{f(z)}{|z|^{n+1}} d\lambda\right| \leq \frac A {r^n} \]
Thus $A$ is as desired.

Using these constants, we can obtain a tail estimate:
\[ \left|\sum_{n \geq N} a_n z^n\right| \leq A \frac{(|z|/r)^N}{1- |z|/r} \leq. \]
In particular we get a bound for $f$ on the unit disc: If $|z|\leq 1$, we get:
\[ |f(z)| \leq A\frac r{r-1}. \]
More information on how to calculate these constants (for example for the product of two such functions) can be found in \ref{}. The most important part of the source for our intentions will be Theorem 3.3. The proof of this Theorem in particular specifies how constants $k'$ and $A'$ for the derivative $f'$ can be found, namely:
\[ k' := 2 k \]
and
\[ A' := \left\lceil \frac{A}{r} \left(1+ \frac{2k}{e \ln(2)}\right)\right\rceil. \]
Since any bound of $f'$ on the unit disc is also a bound of the Lipschitz constant of $f$, this allows us to explicitly calculate a Lipschitz constant
\[ L := \left\lceil A \frac{\left(1 + \frac{2k}{e\ln(2)}\right)}{r-\sqrt{r}}\right\rceil \]
for $f$ with very little computational effort.

We have used the ceiling function above. In terms of computable analysis, this function is not well behaved (since it is not continuous, it will not be computable). Thus we will use the function $x \mapsto \ir{round2}(x) +1$ as a replacement. Here \ir{round2}() is a multivalued function already implemented in \irram.

\section{\irram}

At first glance the most reasonable approach to computable analysis would be to represent a real number $x$ by an algorithm $P$ taking a natural number $n$ and returning an approximation, i.e. a appropriately encoded rational number $x_n$ such that $|x-x_n|<2^{-n}$. This kind of proceeding bears the following problems:
\begin{itemize}
\item Each time a sum or a product of real numbers is calculated, the algorithms of the corresponding real numbers must be copied or at least referenced. This leads to a tree-like structure of any Program and often to uncontrollable growth of memory consumption.
\item A algorithm $P$ encoding a real number carries more information than the real number itself. If $P$ is given to a function, this function can for example also use the running time of $P$ to generate its output. This kind of functions should from a mathematical point of view not be considered computable, and can lead to pathological behavior.
\end{itemize}

Thus the \irram chooses a different approach. Namely the real numbers are represented by finite intervals containing said real number. All manipulations are carried out with these intervals. If a situation occurs, where the precision is simply not sufficient anymore, the whole calculation is restarted with higher precision. This procedure is called a \emph{reiteration}.

This proceeding seems to be very time consuming since the computation my be restarted repeatedly. But it is well known, that this does not blow up the asymptotic complexity: More precisely, the asymptotic complexity of the whole computation and the last reiteration coincide.

\irrams approach does not suffer the problems listed above, but brings its own (which are hopefully more manageable):
\begin{itemize}
\item If the program includes in and output, a restart of the program will lead to doubled output. This is mainly a implementation problem and can be avoided by using the output methods provided by \irram.
\item If on the other hand, the program asked the user for input at some point, this input will have to be memorized. Moreover: if any multivalued function is computed, it has to evaluate to the exact same value in the next run and has to be memorized. This is to avoid incoherences in output.
\item Each time a reiteration is triggered, the whole program restarts. This means, that nearly everything (as mentioned above some things are memorized) is reevaluated. In particular: If the program is composed of two tasks, and one of those needs a higher precision, both tasks will be carried out in this higher precision. This means, that reiterations are very expensive in terms of computation time.
\end{itemize}

Another point is, that programs for \irram are written in \cc. Since \cc is a very powerful programing language, it is often possible for the user to do things he is not really supposed to do. We will encounter this problem ourselves in \ref{}.

We will now consider some parts of \irram more closely.

\subsection{\irrams output functions}

We did already mention, that output in \irram can be a problem and that one should use the output methods provided by \irram. To cope with the difficulties of duplicated output, \irram has its own class of streams \irram::\ir{orstream}, which replaces the standard output streams. The following can be used for output:
\begin{itemize}
\item The \irram::\ir{orstream} \irram::\ir{cout} via overloaded \ir{<<} operators.
\item The functions \irram::\ir{rwrite}, \irram::\ir{rwritee} and \irram::\ir{rshow}.
\item The function \irram::\ir{rfprint}.
\end{itemize}
In the following we will leave the preceding \irram:: away. This coincides with the syntax used inside of \irram programs. One should note, that \ir{cout} differs from \texttt{std::cout}: Pointers will be output as $1$ if they point somewhere and as $0$ if they do not. This is important, since pointer addresses can change in reiterations, which could lead to inconsistent output.

The first point in the list above does play a special role here, since it is used by all the others. They call the function \ir{swrite}, which prints a \ir{REAL} to a string and then output this value through the \ir{cout} by using the \ir{<<} operator.

Thus we will first take a closer look at the class \ir{orstream}. The main components of an \ir{orstream} are:
\begin{description}
\item[\code{target}:] An \texttt{std::ostream} pointer, used for output.
\item[\code{requests}:] A static but thread specific request counter.
\item[\code{outputs}:] A static but thread specific output counter.
\item[\code{real\_w}:] A standard value for the output width of real numbers.
\item[\code{real\_f}:] \ref{}.
\end{description}
The output operator \code{<<} is defined for most standard data types of \cc, and for the \irram specific data types like \ir{REAL}, \ir{DYADIC}, \ir{RATIONAL}, \ir{INTEGER} and \ir{COMPLEX}.

Lets assume the operator \code{<<} is called with some \ir{orstream} \code{ors} and some standard \cc data type \code{x}. \code{ors} will then increase the counter \code{requests}, check if \code{requests} is bigger than \code{outputs}, and if so to pass \code{x} to the \ir{std::ostream} pointed at by target and also increase the counter \code{outputs}. If now a reiteration occurs, the counter \code{requests} will be reset, but the counter \code{outputs} will be kept. This leads to the following behaviour: In the next iteration first \code{outputs} outputs will be ignored, these are evidently exactly those which where already printed in one of the earlier iterations.

If the operator \code{<<} is called with some \code{x} of \irram specific data type, then \code{ors} will call the function \ir{swrite} with parameter \ir{real\_w}, which will print \code{x} to a string \code{xs} of length \ir{real\_w}. Then \code{ors} will call \code{ors << xs}. Since the precision of \code{x} may not suffice to extract a string representing \code{x} of the desired length, \ir{swrite} might trigger a reiteration.

We emphasize once more: It is important to acknowledge the restrictions of the \ir{orstream}s. If you could output pointer addresses, these would change in reiterations. Since output once written will not be revised, these might be wrong in later iterations. In this case the \irram takes care of the problem by not outputting pointer addresses but first casting them to \code{bool}s. \temp{A real example: if you output the error of some REAL it might show values greater than one, which might not reflect the future behaviour as the very next command could be to output the REAL, which will then trigger a reiteration and increase precision. Since the output will not be revised the result could be confusing for the user. This is put down in red, since it might be considered a bug and removed in future versions.} Although these problems should be handled by \irram itself, it is clear that there will always be some ways to trick the system and it is advised to handle output with care.

The remaining output functions simply call the function \ir{swrite} with the desired precision and then hand the string to \irrams standard \ir{orstream} \ir{cout}.

\subsection{\irram::\ir{FUNCTION}s}

We aim to implement a type for analytic functions in \irram, which is not yet present. But there already is a type of functions implemented. We will give a short review of this type.

\subsection{Limits}

\section{Some tools from the \ccOx standard template library}

In \cc, there are four kinds of functional objects: functions, member functions, function pointers and member function pointers. Since the first two are very common, we will start at function pointers. It is important to note, that function pointers, in contrast to regular pointers, do not point to a chunk of memory where a function is located, but to a the piece of code where the function is defined. This makes it impossible to dynamically create new functions when needed, which is a serious shortcoming for us, since we want to be able to add and multiply functions. Member function pointer actually solve this problem, since classes, and with them their member functions, can be dynamically created and destroyed. Really using member functions would be very involved, luckily for us \ccOx added improved syntax for exactly this.

We will in the following sections review the tools we need to handle functions and their dependencies.

\subsection{\texttt{std::function}s}

The std::function template is a general-purpose polymorphic function wrapper (according to cppreference.com). A \texttt{std::function} can be defined by
\begin{lstlisting}
std::function<RESULT(PARAM)> f;
\end{lstlisting}

A std::function can be evaluated like a function, and defined from a function pointer, as the following short example shows:
\begin{lstlisting}
#include<functional>

using std::function;

double f(int i) {
	return double(i);
}

int main()
{
	function<double(int)> g = f;
	cout << g(4) << endl;
	return 0;
}
\end{lstlisting}
The std::function can do a lot more than regular functions though, as we will see in the coming chapters.

The syntax \texttt{function<RESULT(PARAM)>} of \texttt{std::function}s seems nicer than the \texttt{FUNCTION<PARAM, RESULT>} we have seen before. It is also more convenient, since confusing parameter and result type gets a lot harder. The former syntax is implemented by a template specialisation. The definition of looks like this:
\begin{lstlisting}
template<class T>
class function {};

template<class T, class S>
class function<T(S)> {/*...*/};
\end{lstlisting}
Here the first two lines define an empty template class, then lines four and five specialize the definition in the case, that the template argument is of a specific form. Namely a string of the form T(S), where T and S are some arbitrary types. We will use this trick to also improve the syntax of our function type.

\texttt{std::function}s are in many respects superior to \cc functions, but they lack one thing functions do have: the possibility to have templates.


\subsection{The \cc lambda calculus}\label{sec: The cc lambda calculus}

One of the main sources for \texttt{std::functions} is the \cc lambda calculus. A lambda expression in \cc is of the form
\begin{lstlisting}
[/*captures*/](/*parameters*/) -> /*output_type*/ {/*algorithm*/};
\end{lstlisting}
Where the commented parts are to be replaced as follows:
\begin{description}
\item[\textcolor{commentgray}{\code{/*captures*/}}] is to be replaced by a list of variables of local scope, that are needed by the algorithm but supposed to appear as parameters of the function (those are actually what mathematicians mean, when they say \lq parameters\rq). A variable occurring in this list will be called captured (by the lambda function). Global variables need not be captured and can be accessed from the algorithm anyway. Variables may be captured by copy or, if they are preceded by an \lq\texttt{\&}\rq, by reference.
\item[\textcolor{commentgray}{\code{/*parameters*/}}] is to be replaced by the list of parameters of the function to be constructed.
\item[\textcolor{commentgray}{\code{/*output\_type*/}}] is to be replaced by the output type of the function to be constructed (if the value that follows the return command is not of this type, a implicit type conversion will be attempted). This part (together with the \lq\texttt{->}\rq) can be omitted if the output type will be clear from the context.
\item[\textcolor{commentgray}{\code{/*algorithm*/}}] is to be replaced by the algorithm calculating the return value from the parameters and the captured variables.
\end{description}
an easy example of a definition of a \texttt{std::function} via the \cc lambda calculus could look like this:
\begin{lstlisting}
int i = 5;
std::function f<double(int)> = [i](const int& n) {i*log(n);};
\end{lstlisting}
Here the output type was omitted, since it is specified in the \texttt{std::function}.

We remark, that members can not be captured directly: if \texttt c is an object of an class \texttt C, which has a member k of type T, then
\begin{lstlisting}
[c.k]() -> T {return c.k;};
\end{lstlisting}
will not work. The reason is the following: Assume the class C has some member function f changing the value of k. In this case
\begin{lstlisting}
[&c, c.k]() -> T {c.f(); return c.k;};
\end{lstlisting}
would be ambiguous, since c.k could mean both the field of the object c captured by reference, which has the new value, or the member c.k, which was captured by copy before the change was made and therefore should have the old value.

Thus we will have to first copy the member to a local variable, then capture it.

\subsection{\texttt{std::shared\_ptr}s}

A shared pointer is an object consisting of an pointer (to an object of specified type) and a pointer to an reference counter. Each time the shared pointer is copied the reference counter will be increased. If a shared pointer is destroyed, it decreases the reference counter and checks if it is zero, and if it is, it destroys the object it is pointing to.

Shared pointers are very useful for treelike ownership relations: If one object is used by multiple other objects, each of the latter can, instead of an pointer or a copy, to the former hold a shared pointer. This way it is guaranteed, that we neither have useless copies, nor memory leaks because no one feels responsible for destroying.

The \texttt{std::shared\_ptr} can be dereferenced by a preceding $*$, just as a regular pointer, can be constructed from regular pointers and compared to the \NULL. Here is an short example:

\begin{lstlisting}
double* ptr = new double(4.5);
std::shared_ptr<double> s_ptr(ptr);
cout << *s_ptr << endl;
\end{lstlisting}
returns \lq 4.5\rq.

There are two main sources of errors when handling shared pointers:
\begin{itemize}
\item Multiple shared pointers are constructed from the same pointer: In this case each shared pointer keeps its own reference counter. If the first of those counters hits zero, the object will be destroyed. If now a shared pointer following an other reference counter tries to access the object, there will be an error.
\item Circular ownership relations: for simplicity lets have a look at the case of two lonely shared pointers pointing at each other. Each of the pointers has a reference counter which is one (since they are lonely). now assume we destroy one of them. This will decrease the corresponding reference counter and, since the reference count will hit zero, destroy the other shared pointer. This in turn will decrease its reference counter, which will also hit zero. Therefore it will attempt to destroy the first shared pointer. Which is already destroyed. This will lead to an error.
\end{itemize}

\section{putting stuff together}

We will introduce the following classes:
\begin{description}
\item[\func{FUNC<RESULT(PARAM)>}] will be a new class, replacing \irrams class \ir{FUNCTION<PARAM, RESULT>}, relying heavily on the tools provided by the \ccOx standard template library instead of implementing reference counters and stuff by hand.
\item[\func{BASE\_ANALYTIC<ARG>}] will be a class implementing analytic functions with REAL coefficients, that coincide with their Taylor expansion on the closed unit disc. This class will be derived from the class \func{FUNC<ARG(ARG)>}. Some of the functionalities of this class will be exported to the following two classes, in the hope that they might prove useful on their own.
\item[\func{POWERSERIES<coeff\_type>}] will implement formal power series. This is, functions from the integers to objects of type \code{coeff\_type}, but with the convolution replacing the point wise product and the function \code{get\_coeff} to avoid the operator \code{()}, which in this case might be ambiguous, since it could mean both the evaluation as function from the integers to \code{coeff\_type} or analytic function. Also a formal derivative and anti derivative will be implemented.
\item[\func{POLY<coeff\_type>}] will implement polynomials and be very close in its implementation to the type \func{POWERSERIES<coeff\_type>}
\end{description}

There will be one additional helper class \func{coeff\_fetcher<coeff\_type>}, to improve the speed at which the coefficients can be calculated.

\subsection{the class \texttt{FUNC}}

This class is supposed to model (computable) functions. It will mainly consist of an shared pointer to a \texttt{std::function} (called algorithm). Since the algorithm may be used by multiple functions, it will be a constant. Changing the algorithm will be done by creating a new one and reassigning the shared pointer. If the algorithm is not used by any other function, it will automatically be removed. Here is the class definition of FUNC:
\begin{lstlisting}
template<class PARAM, class RESULT>
	class FUNC<RESULT(PARAM)> {
		// members:
			protected:
				shared_ptr<const function<RESULT(const PARAM&)> algorithm;
		// constructors:
			public:
				FUNC(const alg_func<PARAM, RESULT>& f);
			protected:
				FUNC();
		// standard operators:
			public:
				FUNC& operator = (const FUNC<RESULT(PARAM)>&);
				FUNC operator = (const function<RESULT(PARAM)>&);
				friend FUNC<RESULT(PARAM)> operator - <> (const FUNC<RESULT(PARAM)>&);
				friend FUNC<RESULT(PARAM)> operator * <> (const RESULT&, const FUNC<RESULT(PARAM)>&);
				friend FUNC<RESULT(PARAM)> operator + <> (const FUNC<RESULT(PARAM)>&, const FUNC<RESULT(PARAM)>&);
				friend FUNC<RESULT(PARAM)> operator * <> (const FUNC<RESULT(PARAM)>&, const FUNC<RESULT(PARAM)>&);
				friend FUNC<RESULT(PARAM)> operator / <> (const FUNC<RESULT(PARAM)>&, const FUNC<RESULT(PARAM)>&);
				friend FUNC<RESULT(PARAM)> operator - <> (const FUNC<RESULT(PARAM)>&, const FUNC<RESULT(PARAM)>&);
				template<class PAR>
				FUNC<RESULT(PAR)> operator () (const FUNC<PARAM(PAR)>&);
				RESULT operator () (const PARAM&) const;
	};
\end{lstlisting}
Lets take a closer look at the class definition.
\begin{description}
\item[\code{members}:] In line 5 we listed as indicated before the main component of the class: The algorithm function, which is a shared pointer to a constant function of the desired type.
\item[\code{constructors}:] There are two main constructors: We can construct a \func{FUNC} from a algorithm, and there is an empty constructor. The empty constructor is protected, since a FUNC without an algorithm is pretty much useless but it might be convenient to have an empty constructor for the derived classes.
\item[\code{standard operators}:] All the standard operators will be overloaded for \func{FUNC}s. For improved symmetry the operators are external and thus represented by friend templates in the class definition. The composition is a exception to this rule: Since it is not possible to define new operators, the composition (line 22) will have the syntax $f(g)$ instead of $f\circ g$. This requires it to be a member of \func{FUNC}, since the operator \code{()} has to be.
\end{description}

The implementations of this class are very straight forward. We will only take a look at the composition, as an example of how to combine shared pointers to \code{std::function}s and the \cc lambda calculus:
\begin{lstlisting}
template<class PARAM, class RESULT>
template<class PAR>
FUNC<RESULT(PAR)> FUNC<RESULT(PARAM)>::operator () (
	const FUNC<PARAM(PAR)>& f
) {
	if((algorithm = NULL)||(f.algorithm = NULL))
		return FUNC<RESULT(PAR)>();
	alg_ptr<PARAM, RESULT> _algorithm = algorithm;
	alg_ptr<PAR, PARAM> f_algorithm = f.algorithm;
	alg_ptr<PAR, RESULT> new_algorithm(new const auto function(
		[_algorithm, f_algorithm](const PAR& x) -> RESULT {
			return (*_algorithm)((*f_algorithm)(x));
		}
	));
	return FUNC<RESULT(PAR)>(new_algorithm);
}
\end{lstlisting}
Here we used the abbreviation \code{alg\_ptr<PARAM, RESULT>} for \code{shared\_ptr<const function<RESULT(const PARAM\&)>}. First we check, that both the functions have algorithms (line 6). If one of them does not, we return a function without an algorithm. Next we save the algorithms of both functions to local variables (compare the end of \cref{sec: The cc lambda calculus}). In line 10 we define a new function via the \cc lambda calculus. The lambda expression captures the local variables we defined by copy and returns upon input the composition of the two algorithms. Since the new algorithm owns shared pointers to the algorithms of the functions to be composed, these algorithms will not be deleted before the new algorithm is destroyed. Finally in line 8 we return a function with the composition of the algorithms as algorithm.


\subsection{the class \texttt{POWERSERIES}}

\subsection{the class \texttt{BASE\_ANALYTIC}}

\end{document}